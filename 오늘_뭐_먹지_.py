# -*- coding: utf-8 -*-
"""오늘 뭐 먹지?.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1xzz-TwJb3W1Fzu9F68UecIrfHFzew1ym

# 오늘 뭐 먹지?

**이 글은 파이썬으로 데이터 주무르기 책 내용을 응용하여 제작 되었습니다.

밥은 먹어야 하는데 무엇을 먹어야 할 지 고민하며 **오늘 뭐 먹지?**라는 생각을 해보신 적 있으신가요??

아마 대부분이 한번쯤은 해본 적 있으실 것이라고 생각합니다.

그래서 네이버 지식in에서 **오늘 뭐 먹지?**라고 물어 보았을 때 가장 많이 추천된 메뉴를 알아보려고 합니다.

진행 방식은 다음과 같습니다.

1.네이버 지식in에 오늘 뭐 먹지?라고 검색한 후 웹크롤링을 통해 데이터 수집

2.수집된 데이터를 konlpy를 통해 형태소 단위로 토큰화 한 후 워드 클라우드로 만들어 가장 많이 추천된 메뉴가 무엇인지 알아보기

3.word2vec를 활용하여 많이 추천된 메뉴외 유사한 단어를 알아보기

### 지식in에 '오늘 뭐 먹지'라고 검색한 후 해당 페이지 웹크롤링 하기
"""

# Commented out IPython magic to ensure Python compatibility.
import pandas as pd
import numpy as np

import platform
import matplotlib.pyplot as plt
import matplotlib.font_manager as fm

# %matplotlib inline

# 폰트 설정
!apt-get update -qq
!apt-get install fonts-nanum* -qq

path = '/usr/share/fonts/truetype/nanum/NanumGothicEco.ttf'
font_name = fm.FontProperties(fname=path, size=10).get_name()

plt.rc('font', family=font_name)

fm._rebuild()
plt.rcParams['axes.unicode_minus'] = False

# 웹 크롤링
from bs4 import BeautifulSoup
from urllib.request import urlopen
import urllib
import time

from tqdm import tqdm_notebook

eat_text= []

tmp1 = 'https://search.naver.com/search.naver?where=kin'
html = tmp1 + '&kin_display=10&qt=&title=0&&answer=0&grade=0&choice=0&sec=0&nso=so%3Ar%2Ca%3Aall%2Cp%3Aall&query={key_word}%3F&c_id=&c_name=&sm=tab_pge&kin_start={num}&kin_age=0'

for n in tqdm_notebook(range(1, 1000, 10)): #1000개의 검색 결과 읽어오기
  response = urlopen(html.format(num=n, key_word=urllib.parse.quote('오늘 뭐 먹지')))
  soup = BeautifulSoup(response, "html.parser")
  tmp = soup.find_all('ul',class_='lst_total _list')

  for line in tmp:
    eat_text.append(line.text)

  time.sleep(0.5)

eat_text

"""### 수집된 데이터를 konlpy를 통해 형태소 단위로 토큰화 한 후 워드 클라우드 만들기"""

# 한국어 자연어 처리를 위한 konlpy 설치
pip install konlpy

import nltk
from konlpy.tag import Twitter; t=Twitter()

# 하나의 텍스트로 작성
ate_text = ''

for each_line in eat_text[:1000]:
  ate_text = ate_text + each_line + '\n'

# 토큰 모으기
tokens_ko = t.morphs(ate_text)
tokens_ko

ko = nltk.Text(tokens_ko, name="오늘 뭐 먹지")
print(len(ko.tokens)) #토큰으로 모은 단어의 총 개수
print(len(set(ko.tokens))) # 중복 단어를 뺀 개수

# 가장 많이 사용된 단어 보기
ko = nltk.Text(tokens_ko, name = '오늘 뭐 먹지')
ko.vocab().most_common(100)

# 쓸모 없는 단어 제거
stop_words = ['.','하루','요리','먹을까','채택','재료','만들어','많이','도움','내공','시켜','다른','저장','Keep','뭐','오늘','먹지','에','Q','하기','문서','바로가기','A','1:1','?','저녁','****','추천',',','이','점심','요','...','은','을','좀','먹을까요','신','!','가','~','는','도','저','에서','들','고민','로','를','1','..','먹을지','만','의','보세요','한','2021.03','것','나','~~','07','??',')',')','해주세요','하고','입니다','(','한번','3','중','합니다','때','수호','<','>','20','-','네','!!','2021.04','2','드셔','샵','2019.10','^^','드세요','직접','식물','코로나','♡','/','집','인데','제','해서','랑','거','2020.05','06','으로','다','수','안녕하세요','12','10','잘','먹을','03','2020.06','2021.05']

tokens_ko = [each_word for each_word in tokens_ko if each_word not in stop_words]

ko = nltk.Text(tokens_ko, name='오늘 뭐 먹지')
ko.vocab().most_common(100)

# 등장 빈도수 그래프 그리기
plt.figure(figsize=(20,6))
ko.plot(50)
plt.show()

# 워드 클라우드 만들기
from wordcloud import WordCloud, STOPWORDS

data = ko.vocab().most_common(300)

wordcloud = WordCloud(font_path='/usr/share/fonts/truetype/nanum/NanumGothicEco.ttf',relative_scaling = 0.5, background_color = 'white').generate_from_frequencies(dict(data))

plt.figure(figsize=(16,8))
plt.imshow(wordcloud)
plt.axis("off")
plt.show()

"""치킨, 떡볶이, 라면 순으로 추천이 많이 되었다는 것을 확인할 수 있습니다.

### word2vec를 활용하여 많이 추천된 메뉴와 유사한 단어 알아보기
"""

import gensim
from gensim.models import word2vec

# 조사, 어미 등 제거하기

twitter = Twitter()
results = []
lines = eat_text

for line in lines:
  malist = twitter.pos(line, norm=True, stem= True)
  r = []

  for word in malist:
    if not word[1] in ["Josa",'Eomi','Punctuation']:
      r.append(word[0])

  r1 = (" ".join(r)).strip()
  results.append(r1)
  print(r1)

# 데이터 저장
data_file = 'ate_data'
with open(data_file,"w",encoding='utf-8') as fp:
  fp.write('\n'.join(results))

# word2vec 실행 및 저장
data = word2vec.LineSentence(data_file)
model = word2vec.Word2Vec(data, size = 200, window=10, hs=1, min_count=2, sg=1)

model.save('ate.model')

model = word2vec.Word2Vec.load("ate.model")

model.most_similar(positive=['떡볶이']) # 떡볶이는 같은 분식인 순대와 가장 유사한 것으로 나타났습니다.

model.most_similar(positive=['치킨']) # 치킨은 피자와 유사한 단어로 나타났습니다. 또한 뿌링클이라는 유명한 치킨 메뉴도 유사한 단어로 나왔습니다.

model.most_similar(positive=['라면']) #라면은 뜨거운 음식인 만큼 뜨끈하다, 짬뽕 같은 단어가 유사한 단어로 나타났습니다.

"""여기까지 오늘 뭐 먹지?라는 주제로 네이버 지식in을 통해 사람들이 추천하는 메뉴를 살펴보았습니다.

역시 연간 1인당 라면 소비량 2위(78개) 답게 라면을 추천하는 사람들이 많았고

치킨, 떡볶이도 평소에 부담없이 간단하고 맛있게 먹을 수 있는 음식인 만큼 추천하는 사람도 많았던 것 같습니다.
"""

